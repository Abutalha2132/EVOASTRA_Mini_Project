# EVOASTRA_Mini_Project
Internship Mini Project: Python-based web scraping project that collects job data from websites, cleans the data, and performs basic EDA and visualizations to analyze job market trends.
Web Scraping Mini Project

Internship Mini Project – EVOASTRA

# Project Overview

This project is an internship mini project developed under EVOASTRA, focused on building an end-to-end web scraping and data analysis pipeline using Python.
The project demonstrates how real-world data can be collected from websites, cleaned, analyzed, and visualized in a structured and ethical manner.

The main objective is to automate job data collection, reduce manual effort, and extract meaningful insights from the scraped data.

# Objectives

To understand how web scraping works in real-world scenarios

To extract structured data from static and dynamic websites

To clean and prepare raw scraped data for analysis

To perform basic Exploratory Data Analysis (EDA)

To visualize insights for better understanding and presentation

# Tools & Technologies Used

Python – Core programming language

Requests – For scraping static web pages

Playwright – For handling dynamic and JavaScript-rendered content

BeautifulSoup – For parsing HTML and extracting data

Pandas – For data cleaning, transformation, and storage

CSV – For saving structured datasets

Matplotlib / Seaborn – For data visualization

# Project Workflow

Website Analysis

Identify static and dynamic pages

Inspect HTML elements to locate required data

Web Scraping

Use Requests for static content

Use Playwright for dynamic content loading

Extract job details such as title, company, location, etc.

Data Cleaning

Remove duplicate records

Handle missing or null values

Standardize column names and text formats

Data Storage

Store cleaned data into CSV files for further use

Exploratory Data Analysis (EDA)

Analyze job distribution

Identify trends and patterns

Generate summary statistics

Data Visualization

Create charts and graphs

Visualize job roles, locations, and frequencies

# Key Learnings

Difference between static and dynamic web scraping

Practical use of Playwright for real-world websites

Importance of data cleaning before analysis

How EDA helps in understanding datasets

Presenting insights using visualizations

# Challenges Faced

Handling dynamically loaded content

Dealing with empty or inconsistent data

Managing duplicates and missing values

# Outcome

Successfully scraped and cleaned job-related data

Generated meaningful insights through EDA

Visualized trends for easy interpretation

Gained hands-on experience with real-world data pipelines

# Internship Acknowledgement

This project was completed as part of an Internship Mini Project under EVOASTRA, aimed at providing practical exposure to data scraping, processing, and analysis using Python.

 Author

Team C Evoastra Ventures- Batch1201 CP39
Intern – EVOASTRA
